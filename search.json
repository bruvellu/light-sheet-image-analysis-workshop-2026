[
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Datasets\nFind here the example datasets available for the course.",
    "crumbs": [
      "Datasets"
    ]
  },
  {
    "objectID": "talks/talk_machine_learning.html",
    "href": "talks/talk_machine_learning.html",
    "title": "Machine learning",
    "section": "",
    "text": "Machine learning\n\nPixel Classification Theory\n\nExamples: ilastik, weka, APOC, labkit",
    "crumbs": [
      "Talks",
      "Machine learning"
    ]
  },
  {
    "objectID": "talks/talk_experimental_design.html",
    "href": "talks/talk_experimental_design.html",
    "title": "Experimental design and sample mounting",
    "section": "",
    "text": "Experimental design and sample mounting\n\nExperimental setup\n\nRecognizing image artifacts\nTouch upon clearing, but focus on showing who (or which review article) to refer to.\n\n(Talk adapted from Marina‚Äôs LISH 2025 talk)",
    "crumbs": [
      "Talks",
      "Experimental design and sample mounting"
    ]
  },
  {
    "objectID": "talks/talk_digital_images.html",
    "href": "talks/talk_digital_images.html",
    "title": "Visualization and processing of digital images",
    "section": "",
    "text": "Visualization and processing of digital images\n\nWhat is an image? (bit depth, voxel size)\n\nCameras?\n\nHistograms\n\nLUT\n\nDimensions\n\nB+C\n\nFormats (focus on HDF5)\n\nBased on this lecture",
    "crumbs": [
      "Talks",
      "Visualization and processing of digital images"
    ]
  },
  {
    "objectID": "talks/talk_welcome.html",
    "href": "talks/talk_welcome.html",
    "title": "üî¨ Light-Sheet Image Analysis Workshop 2026",
    "section": "",
    "text": "Marina can give the welcome talk. We can ask Anibal what information to mention in here. Otherwise acknowlege funding bodies, introduce the instructors and organizers. Maybe also put the students in teams of 2 (do we do this or we let them self organise?) Introduce course materials.",
    "crumbs": [
      "Talks",
      "Talk Welcome"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Warning\n\n\n\nThis website is under construction!\n\n\nWelcome! This website contains the materials for the Light-Sheet Image Analysis Workshop organized by the Light-Sheet Imaging at Universidad Mayor (LiSIUM). The course will be held at the Center for Integrative Biology of Universidad Mayor between 5‚Äì9 January 2026 in Santiago, Chile.\n\n\nProgram Resources\n\n\n\nThe Light-Sheet Image Analysis Workshop is aimed at scientists at all levels and facility staff who wish to receive training in quantitative image analysis from multidimensional light-sheet microscopy data.\nThe workshop is composed of theory sessions in the mornings and practical sessions in the afternoon. Participants will work on projects using the provided datasets or their own data and perform short presentations with what they learned and achieved during the course.\n\n\n\n\n\nAn√≠bal Vargas R√≠os\nLuz Mar√≠a Fuentealba\nCharlotte Buckley\n\n\n\n\n\n\nMarina Cuenca\nAgust√≠n Corbat\nBruno Vellutini"
  },
  {
    "objectID": "index.html#shortcuts",
    "href": "index.html#shortcuts",
    "title": "Home",
    "section": "",
    "text": "Program Resources"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Home",
    "section": "",
    "text": "The Light-Sheet Image Analysis Workshop is aimed at scientists at all levels and facility staff who wish to receive training in quantitative image analysis from multidimensional light-sheet microscopy data.\nThe workshop is composed of theory sessions in the mornings and practical sessions in the afternoon. Participants will work on projects using the provided datasets or their own data and perform short presentations with what they learned and achieved during the course.\n\n\n\n\n\nAn√≠bal Vargas R√≠os\nLuz Mar√≠a Fuentealba\nCharlotte Buckley\n\n\n\n\n\n\nMarina Cuenca\nAgust√≠n Corbat\nBruno Vellutini"
  },
  {
    "objectID": "practicals/practical_2d/index.html",
    "href": "practicals/practical_2d/index.html",
    "title": "Visualization of 2D images",
    "section": "",
    "text": "Visualization of 2D images\n\nOpening an image\n\nExploring dimensions, scale, formats, bits, metadata\n\nB+C\n\nLUTs\n\nScalebar",
    "crumbs": [
      "Practicals",
      "Visualization of 2D images"
    ]
  },
  {
    "objectID": "practicals/practical_segmentation/index.html",
    "href": "practicals/practical_segmentation/index.html",
    "title": "Post-processing, segmentation and labelling",
    "section": "",
    "text": "In this exercise we will:\n\nCompare global and local thresholding methods and understand when each is useful.\n\nImprove segmentation using background subtraction and Gaussian smoothing.\n\nRefine masks using binary operations, including Fill Holes and Kill Borders.\n\nGenerate labeled objects using MorphoLibJ‚Äôs Connected Components Labeling.\n\nExtract object-level measurements (area, perimeter, circularity, etc.).\n\nVisualize measurement values on labeled images.\n\nFilter segmented objects based on size or other properties.\n\nThese steps form a complete workflow: raw image ‚Üí pre-processing ‚Üí segmentation ‚Üí cleanup ‚Üí labeling ‚Üí measurement ‚Üí filtering\nWe‚Äôll use MAX_Lund.tif as the example image https://zenodo.org/records/17986091\nRequirements: - Fiji - MorphoLibJ plugin https://imagej.net/plugins/morpholibj\n\n\n\nStart Fiji.\n\nOpen the image:\nFile ‚Üí Open‚Ä¶ ‚Üí MAX_Lund.tif\n\nOpen the histogram and visualization tools:\nImage ‚Üí Adjust ‚Üí Brightness/Contrast‚Ä¶\n\nYou should see a histogram like this:\n\n\n\nBrightness/Contrast histogram\n\n\nIdea: Thresholding chooses an intensity value that separates ‚Äúforeground‚Äù from ‚Äúbackground‚Äù. The histogram shows how many pixels exist at each intensity.\n\n\n\nGlobal thresholding applies one single threshold to the whole image.\n\nWith MAX_Lund.tif active, run:\nImage ‚Üí Adjust ‚Üí Auto Threshold‚Ä¶\nChoose:\n\nMethod: Try all\n\nWhite objects\n\n\nConfirm.\n\nFiji generates a montage of all global methods:\n\n\n\nGlobal auto threshold montage\n\n\n\n\n\nLocal thresholding requires 8-bit input.\n\nSelect the original image:\nWindow ‚Üí MAX_Lund.tif\nConvert to 8-bit:\nImage ‚Üí Type ‚Üí 8-bit\n\nNow the image is ready for local methods.\n\n\n\nLocal thresholding computes a threshold for each local neighborhood.\n\nRun:\nImage ‚Üí Adjust ‚Üí Auto Local Threshold‚Ä¶\nChoose:\n\nMethod: Try all\n\nRadius: 15\n\nParameter 1: 0\n\nParameter 2: 0\n\nWhite objects\n\nConfirm.\n\n\n\n\nLocal auto threshold montage\n\n\n\n\n\nGood segmentation often benefits from reducing background and noise first.\n\n\n\nOpen MAX_Lund.png.\n\nSubtract background:\nProcess ‚Üí Subtract Background‚Ä¶\n\nRolling ball radius: 50\n\n\nSmooth noise:\nProcess ‚Üí Filters ‚Üí Gaussian Blur‚Ä¶\n\nSigma: 1\n\n\nAfter preprocessing:\n\n\n\nAuto Local Threshold after preprocessing\n\n\n\n\n\n\n\n\n\nRun:\nImage ‚Üí Adjust ‚Üí Auto Local Threshold‚Ä¶\n\nMethod: Otsu\n\nRadius: 15\n\n\nLocal Otsu mask:\n\n\n\nLocal Otsu mask\n\n\n\n\n\n\nFill holes inside objects:\nProcess ‚Üí Binary ‚Üí Fill Holes\nSlightly shrink objects:\nProcess ‚Üí Binary ‚Üí Erode\nOptionally restore outlines:\nEdit ‚Üí Draw\nExpand objects after erosion:\nProcess ‚Üí Binary ‚Üí Dilate\n\nRefined mask:\n\n\n\nRefined mask\n\n\n\n\n\n\nRemove partial objects touching image borders:\nPlugins ‚Üí MorphoLibJ ‚Üí Filtering ‚Üí Kill Borders\n\n\n\n\nFilled + border-removed mask\n\n\n\n\n\n\nConvert each connected region into a uniquely labeled object:\nPlugins ‚Üí MorphoLibJ ‚Üí Label ‚Üí Connected Components Labeling\n\nConnectivity: 4\n\nOutput type: 16-bit\n\nLabeled objects:\n\n\n\nConnected components labeling\n\n\n\n\n\nQuantifying each object is often the main goal after segmentation.\nRun measurements:\nPlugins ‚Üí MorphoLibJ ‚Üí Analyze ‚Üí Analyze Regions\nThis extracts a number of morphological associated features. We will select:\n\nArea\n\nPixel count\n\nPerimeter\n\nCircularity\n\nEllipse geometry\n\nBounding box\n\n\n\n\nMorphometry table\n\n\n\n\n\nVisualize one measurement (e.g.¬†area) mapped onto the label image:\nPlugins ‚Üí MorphoLibJ ‚Üí Label Images ‚Üí Assign Measure to Label\nChoose Area and apply a colormap.\n\n\n\nArea visualization on labels\n\n\nUseful for:\n\nspotting unusually big/small objects\n\ndeciding filtering thresholds\n\nchecking measurement correctness\n\n\n\n\nRemove small objects based on size:\nPlugins ‚Üí MorphoLibJ ‚Üí Label Images ‚Üí Label Size Filtering\n\nOperation: Lower Than\n\nSize threshold: 100 px\n\n\n\n\nSize filtering",
    "crumbs": [
      "Practicals",
      "Post-processing, segmentation and labelling"
    ]
  },
  {
    "objectID": "practicals/practical_segmentation/index.html#d-segmentation-in-fiji",
    "href": "practicals/practical_segmentation/index.html#d-segmentation-in-fiji",
    "title": "Post-processing, segmentation and labelling",
    "section": "",
    "text": "In this exercise we will:\n\nCompare global and local thresholding methods and understand when each is useful.\n\nImprove segmentation using background subtraction and Gaussian smoothing.\n\nRefine masks using binary operations, including Fill Holes and Kill Borders.\n\nGenerate labeled objects using MorphoLibJ‚Äôs Connected Components Labeling.\n\nExtract object-level measurements (area, perimeter, circularity, etc.).\n\nVisualize measurement values on labeled images.\n\nFilter segmented objects based on size or other properties.\n\nThese steps form a complete workflow: raw image ‚Üí pre-processing ‚Üí segmentation ‚Üí cleanup ‚Üí labeling ‚Üí measurement ‚Üí filtering\nWe‚Äôll use MAX_Lund.tif as the example image https://zenodo.org/records/17986091\nRequirements: - Fiji - MorphoLibJ plugin https://imagej.net/plugins/morpholibj\n\n\n\nStart Fiji.\n\nOpen the image:\nFile ‚Üí Open‚Ä¶ ‚Üí MAX_Lund.tif\n\nOpen the histogram and visualization tools:\nImage ‚Üí Adjust ‚Üí Brightness/Contrast‚Ä¶\n\nYou should see a histogram like this:\n\n\n\nBrightness/Contrast histogram\n\n\nIdea: Thresholding chooses an intensity value that separates ‚Äúforeground‚Äù from ‚Äúbackground‚Äù. The histogram shows how many pixels exist at each intensity.\n\n\n\nGlobal thresholding applies one single threshold to the whole image.\n\nWith MAX_Lund.tif active, run:\nImage ‚Üí Adjust ‚Üí Auto Threshold‚Ä¶\nChoose:\n\nMethod: Try all\n\nWhite objects\n\n\nConfirm.\n\nFiji generates a montage of all global methods:\n\n\n\nGlobal auto threshold montage\n\n\n\n\n\nLocal thresholding requires 8-bit input.\n\nSelect the original image:\nWindow ‚Üí MAX_Lund.tif\nConvert to 8-bit:\nImage ‚Üí Type ‚Üí 8-bit\n\nNow the image is ready for local methods.\n\n\n\nLocal thresholding computes a threshold for each local neighborhood.\n\nRun:\nImage ‚Üí Adjust ‚Üí Auto Local Threshold‚Ä¶\nChoose:\n\nMethod: Try all\n\nRadius: 15\n\nParameter 1: 0\n\nParameter 2: 0\n\nWhite objects\n\nConfirm.\n\n\n\n\nLocal auto threshold montage\n\n\n\n\n\nGood segmentation often benefits from reducing background and noise first.\n\n\n\nOpen MAX_Lund.png.\n\nSubtract background:\nProcess ‚Üí Subtract Background‚Ä¶\n\nRolling ball radius: 50\n\n\nSmooth noise:\nProcess ‚Üí Filters ‚Üí Gaussian Blur‚Ä¶\n\nSigma: 1\n\n\nAfter preprocessing:\n\n\n\nAuto Local Threshold after preprocessing\n\n\n\n\n\n\n\n\n\nRun:\nImage ‚Üí Adjust ‚Üí Auto Local Threshold‚Ä¶\n\nMethod: Otsu\n\nRadius: 15\n\n\nLocal Otsu mask:\n\n\n\nLocal Otsu mask\n\n\n\n\n\n\nFill holes inside objects:\nProcess ‚Üí Binary ‚Üí Fill Holes\nSlightly shrink objects:\nProcess ‚Üí Binary ‚Üí Erode\nOptionally restore outlines:\nEdit ‚Üí Draw\nExpand objects after erosion:\nProcess ‚Üí Binary ‚Üí Dilate\n\nRefined mask:\n\n\n\nRefined mask\n\n\n\n\n\n\nRemove partial objects touching image borders:\nPlugins ‚Üí MorphoLibJ ‚Üí Filtering ‚Üí Kill Borders\n\n\n\n\nFilled + border-removed mask\n\n\n\n\n\n\nConvert each connected region into a uniquely labeled object:\nPlugins ‚Üí MorphoLibJ ‚Üí Label ‚Üí Connected Components Labeling\n\nConnectivity: 4\n\nOutput type: 16-bit\n\nLabeled objects:\n\n\n\nConnected components labeling\n\n\n\n\n\nQuantifying each object is often the main goal after segmentation.\nRun measurements:\nPlugins ‚Üí MorphoLibJ ‚Üí Analyze ‚Üí Analyze Regions\nThis extracts a number of morphological associated features. We will select:\n\nArea\n\nPixel count\n\nPerimeter\n\nCircularity\n\nEllipse geometry\n\nBounding box\n\n\n\n\nMorphometry table\n\n\n\n\n\nVisualize one measurement (e.g.¬†area) mapped onto the label image:\nPlugins ‚Üí MorphoLibJ ‚Üí Label Images ‚Üí Assign Measure to Label\nChoose Area and apply a colormap.\n\n\n\nArea visualization on labels\n\n\nUseful for:\n\nspotting unusually big/small objects\n\ndeciding filtering thresholds\n\nchecking measurement correctness\n\n\n\n\nRemove small objects based on size:\nPlugins ‚Üí MorphoLibJ ‚Üí Label Images ‚Üí Label Size Filtering\n\nOperation: Lower Than\n\nSize threshold: 100 px\n\n\n\n\nSize filtering",
    "crumbs": [
      "Practicals",
      "Post-processing, segmentation and labelling"
    ]
  },
  {
    "objectID": "practicals/practical_segmentation/index.html#d-segmentation-in-napari",
    "href": "practicals/practical_segmentation/index.html#d-segmentation-in-napari",
    "title": "Post-processing, segmentation and labelling",
    "section": "3D segmentation in Napari",
    "text": "3D segmentation in Napari\nIn this exercise we will:\n\nUse Napari to open a 3D image\nUse Napari assistant to visualize a workflow for 3D image segmentation and labelling\nUse region props to quantify morphological parameters and make colorcoded plots\n\nThese steps form a complete workflow:\nraw image ‚Üí pre-processing ‚Üí segmentation ‚Üí cleanup ‚Üí labeling ‚Üí measurement ‚Üí filtering\nWe‚Äôll use Lund.tif as the example image https://zenodo.org/records/17986091.\nRequirements: - Everything you need is in the toml file in the Pixi/napari-assistant folder\n\n0. Open Napari assistant using Pixi\nIn the terminal, go to the directory Pixi/napari-assistant and run:\npixi run assistant\n\n\n1. Open a 3D stack\nDrag and drop the file or\nFile ‚Üí Open File\n\n\n\nBrightness/Contrast histogram\n\n\nWe will be able to see and explore the stack, and we can change to a 3D rendering with the option Toogle 2D/3D view in the lower left button pannel. We can also make orthogonal views by clicking the button to the right Change order of the visible axis.\nIn the right pannel we will see the Assistant plugin, where it suggests operations in the appropriate order. The amount of operations and options depends on your installed plugins. Some of them are redundant.\n\n\n2. Remove background, binarization and labeling\nSelect Remove Background ‚Üí White top hat  ‚Üí radius = 10\n\n\n\nBrightness/Contrast histogram\n\n\nThen select Binarize ‚Üí Threshold Yen, making sure to select the Result of White top-hat image.\n\n\n\nBrightness/Contrast histogram\n\n\nI recommend looking at the result in 3D.\n\n\n\nBrightness/Contrast histogram\n\n\nFinally, we can select Label ‚Üí Connected component labeling, make sure to select the Result of Threshold image. We can additionally select the exclude on edges option.\n\n\n\nBrightness/Contrast histogram\n\n\nSome of them are stuck together. Let‚Äôs try and fix that.\n\n\n3. Fix labels\nLet‚Äôs select again the previous layer Result of Threshold. Then select Process labels ‚Üí Binary erosion ‚Üí radius = 3. This will reduce the objects of the binary segmentation.\n\n\n\nBrightness/Contrast histogram\n\n\nNow let‚Äôs recreate the labels Label ‚Üí Connected component labeling, make sure to select the Result of Binary Erosion.\nThen Process labels ‚Üí Expand Labels ‚Üí radius = 3. Explore the labels in 3D.\n\n\n\nBrightness/Contrast histogram\n\n\nNow we can accurately measure morphological features of these labels. You can close the assistant pannel now.\n\n\n4. Measure morphological properties\nSelect Tools ‚Üí Measure Tables ‚Üí Object Features/Properties. Here make sure to select the Result of Expanded Labels image. You can select different features, includding intensity features extracted from the raw data. After running a table should appear which can be exported in csv format.\n\n\n\nBrightness/Contrast histogram\n\n\n\n\n\nBrightness/Contrast histogram\n\n\nby double clicking any of the columns of this table, a new layer image will appear with colorcoded labels indicating the value of the selected measurement. Colormaps can be adjusted for preference.\n\n\n\nBrightness/Contrast histogram",
    "crumbs": [
      "Practicals",
      "Post-processing, segmentation and labelling"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html",
    "href": "practicals/practical_tracking/index.html",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "",
    "text": "This is a (very) basic tutorial on how to track cells using Mastodon (Girstmair et al. 2025) in Fiji (Schindelin et al. 2012).\n\nObjectives: load/create Mastodon dataset, get familiar with navigating BigDataViewer and lineage windows, perform basic manual cell tracking with cell divisions, basic editing of lineages, try semi-automated detection and tracking, and some advanced analysis\nWe will use the Mastodon dataset from Girstmair, J. (2024). Mastodon Auto-Tracking Demo on Parhyale hawaiensis Limb Development. Zenodo. https://doi.org/10.5281/zenodo.13944688\nThe original data is from this paper https://elifesciences.org/articles/34410\nMastodon has a detailed documentation. Please check it out for more details https://mastodon.readthedocs.io/",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-summary",
    "href": "practicals/practical_tracking/index.html#sec-summary",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "",
    "text": "This is a (very) basic tutorial on how to track cells using Mastodon (Girstmair et al. 2025) in Fiji (Schindelin et al. 2012).\n\nObjectives: load/create Mastodon dataset, get familiar with navigating BigDataViewer and lineage windows, perform basic manual cell tracking with cell divisions, basic editing of lineages, try semi-automated detection and tracking, and some advanced analysis\nWe will use the Mastodon dataset from Girstmair, J. (2024). Mastodon Auto-Tracking Demo on Parhyale hawaiensis Limb Development. Zenodo. https://doi.org/10.5281/zenodo.13944688\nThe original data is from this paper https://elifesciences.org/articles/34410\nMastodon has a detailed documentation. Please check it out for more details https://mastodon.readthedocs.io/",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-requirements",
    "href": "practicals/practical_tracking/index.html#sec-requirements",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Requirements",
    "text": "Requirements\n\nParhyale dataset\nFiji/ImageJ\nMastodon",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-setup",
    "href": "practicals/practical_tracking/index.html#sec-setup",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Setup",
    "text": "Setup\n\nDownload Dataset\nNote! If you are following this during the course, the dataset has already been downloaded.\n\nGo to https://zenodo.org/records/13944688\nClick to download https://zenodo.org/records/13944688/files/Mastodon_Auto-Tracking_Demo_Ph-limb-dev.zip?download=1\nWait. It‚Äôs a 4.3GB ZIP file\nMove the file to a working directory\nUnzip Mastodon_Auto-Tracking_Demo_Ph-limb-dev.zip\nWait. It‚Äôll be unzipped to 23GB\n\n\n\n\n\n\n\nYour working directory after downloading and unzipping the dataset file.\n\n\n\n\n\n\n\nContents of the dataset directory.\n\n\n\n\n\n\n\nDownload Fiji\n\nGo to https://fiji.sc\nChoose Distribution: Stable\nClick the big download button\nCopy fiji-stable-linux64-jdk.zip to working directory and unzip it\nOpen the new directory fiji-stable-linux64-jdk/Fiji.app/\nDouble-click on fiji-linux-x64 launcher\nFiji will open\n\n\n\n\nInstall Mastodon\n\nClick on Help &gt; Update...\n\n\n\nThe updater will open and say Fiji is up-to-date\nClick Manage Update Sites\n\n\n\n\n\n\n\n\n\n\n\n\nA window will open with a list of plugins available to install in Fiji\n\n\n\nSearch for ‚Äúmastodon‚Äù\n\n\n\nSeveral Mastodon related plugins will appear\nClick on the checkbox for Mastodon\n\n\n\nClick Apply and Close and then Apply Changes\n\n\n\nWait‚Ä¶ until the downloads are finished. Then, click OK\n\n\n\n\n\n\n\n\n\n\n\n\nRestart Fiji (close window and double-click the launcher)",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-open-project",
    "href": "practicals/practical_tracking/index.html#sec-open-project",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Open Mastodon Project",
    "text": "Open Mastodon Project\n\nIn Fiji click on Plugins &gt; Tracking &gt; Mastodon &gt; Mastodon Launcher\n\n\n\nMastodon Launcher window will open\nClick on ‚Äúopen Mastodon project‚Äù (top left) and ‚ÄúOpen another project‚Äù (bottom right)\n\n\n\n\n\n\n\n\n\n\n\n\nNavigate to the directory Mastodon_Auto-Tracking_Demo_Ph-limb-dev/\nSelect the file Parhyale_LimbDev_30tps.mastodon\n\n\n\nSeveral new windows will open (Console, Mastodon, BigDataViewer, TrackScheme, Data table)",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-inspect-dataset",
    "href": "practicals/practical_tracking/index.html#sec-inspect-dataset",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Inspect the Dataset",
    "text": "Inspect the Dataset\n\nLet‚Äôs focus on the Mastodon window. Close Console, BigDataViewer, TrackScheme, Data table\n\n\n\nThis is the main project menu from where you can open windows, set options, process data and save the project\nThe most important buttons for this tutorial are bdv (BigDataViewer) and trackscheme\nClick on bdv and make the window larger\n\n\n\nDrag the timepoint slider at the bottom to see cells moving and dividing\nUsing your acquired BigDataViewer skills, focus on the surface of the embryo\nIf you get lost, press Shift+Z to re-orient the embryo\nFind a cell that divides before timepoint 15 and looks trackable\nZoom on it using Ctrl+Shift+scroll and center it by holding the right button and dragging the mouse\nUse Shift+scroll to navigate through z and M-N to go through time\n\n\n\n\n\n\n\n\n\n\n\n\nYou are ready to track",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-manual-tracking",
    "href": "practicals/practical_tracking/index.html#sec-manual-tracking",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Manual Tracking",
    "text": "Manual Tracking\n\nOn the Mastodon project window, click on the trackscheme button\nThe TrackScheme window will appear\n\n\n\nResize the bdv window to be side-by-side with the TrackScheme\nClick on the bdv window, set the timepoint to some frames before mitosis, Shift+scroll to find the center of the nucleus, put your mouse pointer there and press A\nA round magenta circle will appear over the nucleus and in the TrackScheme\n\n\n\nWith your mouse over the circle, use Shift+Q and Shift+E to adjust the size of the spot to roughly the nucleus diameter\n\n\n\nZoom in on the new spot in the TrackScheme, hover and click on it and watch what happens in the bdv window\n\n\n\nGo back to the bdv, hover the pointer over the circle and hold the spacebar to adjust the position of the circle and the nucleus\n\n\n\nNow let‚Äôs add a second spot\nHover the mouse inside the circle and hold A. This will advance to the next frame showing you the first spot in white dashed line and the second spot in white solid line with a white solid link between the two.\n\n\n\nStill holding A, position the second spot, then release A to create the new linked spot\nCheck how the second spot and a link were created in the TrackScheme automatically\n\n\n\nContinue to track the nucleus for a few more frames, until the frame immediately before division\nNote that when you click on a spot in the bdv window, the corresponding spot is highlighted in the TrackScheme window\nSee what happens to the bdv when clicking the spots in TrackScheme‚Ä¶ (nothing, unless it is the spot in view)\nLet‚Äôs change that\nIn the menu bar of bdv and TrackScheme windows there are locks 1, 2, 3. Click on lock 1 in both windows\n\n\n\nNow click through spots in the TrackScheme; the view in the bdv will change to show the selected spot at the center\n\n\n\nBefore we continue tracking the cell division, let‚Äôs check one of the amazing Mastodon features\nClick on the bdv button in the Mastodon project window and another bdv window will open\n\n\n\nNow activate lock 1 and click on one of the TrackScheme spots; both windows will be synchronized!\n\n\n\nWhy is this useful for manual tracking?\nAdjust the view to center the spot in the second bdv window, press Shift+Y, and select a spot from the TrackScheme. Now we have both XY and ZY views of the same nucleus!\n\n\n\nWhich is great for tracking in 3D. You can check, for instance, that your spot is well centered in Z and adjust it in this window\n\n\n\nContinue the tracking of one of the daughter cells. Select the last spot in the TrackScheme, go to the XY bdv, hover the mouse over the circle and hold A, move the spot, and release A to add it.\nDo it for a few frames\nThen go back to the pre-division spot and add a linked spot corresponding to the other daughter cell\nThis will create the first branch of the lineage tree\n\n\n\nContinue tracking the second daughter cell for a few frames\n\n\n\nIf you zoom out the TrackScheme view you will be able to see the full branched tree",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-semiauto-tracking",
    "href": "practicals/practical_tracking/index.html#sec-semiauto-tracking",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Semi-Automated Tracking",
    "text": "Semi-Automated Tracking\n\nThis mode will try to guess where the next nucleus is and automatically create the spots and links\nTo start, choose a different nucleus to track and press A to add a new spot\n\n\n\nNow, hovering the pointer above the spot press Ctrl+T\nA lineage will appear in the TrackScheme.\n\n\n\nCheck how accurate it is by clicking on the spots and watching their position relative to the nucleus in the bdv windows\nTry going further by hovering on a spot and pressing Ctrl+T to continue the semi-automated tracking. See how long you can go, how it behaves with cell divisions, and which cells work well with it and which don‚Äôt\n\n\n\nThere are many parameters that can be adjusted to tweak the semi-automated tracking behavior, check the documentation",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-auto-tracking",
    "href": "practicals/practical_tracking/index.html#sec-auto-tracking",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Automated Tracking",
    "text": "Automated Tracking\n\nThe final part of this tutorial is to try automatic detection and linking of spots\nThis is the dream: loading your data and getting out your lineage. However, in practice, it‚Äôs a lot messier. Cleaning, fixing, and curating the data is required to get a nice informative lineage\nWe will use a simplified version of the protocol included in this dataset in the file Protocol_Auto-Detection_Auto-Linking.docx\n\n\n\nDetection\n\nIn the Mastodon window, go to Plugins &gt; Tracking &gt; Detection...\n\n\n\nPress Next twice (leave options as is)\n\n\n\n\n\n\n\n\n\n\n\n\nChoose Advanced DoG detector and press Next\nKeep Detect: bright blobs, change Estimated diameter to 35px and Quality threshold to 100. Behavior should remain as Add\n\n\n\n\n\n\n\n\n\n\n\n\nClick Preview and see how well the detection will work by exploring a new bdv window.\n\n\n\nDo you observe too many false positives? You can change the diameter, for example, and try the preview again to see what happens to the detected spots\nOnce satisfied, press Next and wait\n\n\n\nWhen the detection is done, press Finish\n\n\n\nThe bdv windows and the TrackScheme will be showing a lot of new spots.\nExplore the spots in the BigDataViewer and TrackScheme windows. If you zoom in a lot you‚Äôll see the unlinked, individual spots per frame\n\n\n\n\nCleaning\n\nBefore we try to automatically link these spots, let‚Äôs remove low quality detections\nOn the Mastodon window click on Table, resize it to have more space, and resize the column Detection q... to show Detection quality\n\n\n\n\n\n\n\n\n\n\n\n\nClick on Detection quality to sort the table\n\n\n\nClick on the first row to select it. Select all rows where Detection quality is &lt;400\nThen click Edit &gt; Delete Selection\n\n\n\nClose the table\nYou can also manually delete obviously wrong spots by hovering and pressing D. Clean up the ones outside the embryo\n\n\n\nLinking\n\nNow let‚Äôs try linking\nIn the main Mastodon window click on Plugins &gt; Tracking &gt; Linking...\nKeep All spots selected for all timepoints (0-29) and press Next\nChoose Lap linker and click Next\n\n\n\n\n\n\n\n\n\n\n\n\nChange the parameters to:\n\nFrame to frame linking: Max distance to 40px\nGap closing: Max distance to 60px (keep others as is)\nTrack division: Check Allow track division, set Max distance to 40px, and press + to add a Feature penalty and set it to Center ch1 to 0.3\n\nPress Next to start linking and wait‚Ä¶ then press Finish\n\n\n\n\n\n\n\n\n\n\n\n\nNote that there are now tracks in the bdv and TrackScheme windows. Explore them a bit\n\n\n\nMastodon can calculate features (position, displacement, velocity, etc.) of individual spots, links and branches. Let‚Äôs do that\nIn the main Mastodon window press compute features. A Feature calculation window will open\n\n\n\nPress compute and wait‚Ä¶ when it‚Äôs done, close it.\nNote that now the tracks in the BigDataViewer is showing colored links\n\n\n\nOpen the table window from the main window\nIt‚Äôll be filled with computed features",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-feature-visualization",
    "href": "practicals/practical_tracking/index.html#sec-feature-visualization",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Basic Feature Visualization",
    "text": "Basic Feature Visualization\n\nFinally, let‚Äôs visualize the computed features that might be interesting or useful\nIn the bdv window press File &gt; Preferences to open the feature color coding visualization parameters\n\n\n\nOn Settings &gt; Feature Color Modes click on Duplicate (it‚Äôll generate a Number of links (2)) and then Rename. Rename it to Velocity\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Coloring Spots change Read spot color from to Incoming link and change Feature to Link velocity. Then click on autoscale in the range\nOn the Coloring Links change Read link color from to Link and change Feature to Link velocity. Then also click on autoscale\nClick Apply (nothing will happen) then OK\n\n\n\nOn the bdv window press View &gt; Coloring &gt; Velocity\n\n\n\nThe spots and links in the BigDataViewer window will change colors\n\n\n\nDo the same for the other bdv window and the TrackScheme\n\n\n\nThis gives a visual representation of cells which have a high displacement per frame. These might be artifacts in linking unrelated spots or, in a good processed lineage, reveal some biological process like cell migration",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-graph-plotting",
    "href": "practicals/practical_tracking/index.html#sec-graph-plotting",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "Graph Plotting",
    "text": "Graph Plotting\n\nTo finalize, a simple example of plotting\nClick on grapher in the main Mastodon window, a plot window will open\n\n\n\nPress the lock 1 to lock the windows, select Link velocity - outgoing for X axis and Detection quality for Y axis and press Plot\n\n\n\nFind out if the spots with the highest link velocity are properly linked or if it is an artifact",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_tracking/index.html#sec-references",
    "href": "practicals/practical_tracking/index.html#sec-references",
    "title": "Cell tracking using Mastodon in Fiji",
    "section": "References",
    "text": "References\n\n\nGirstmair, Johannes, Tobias Pietzsch, Vladimir Ulman, Stefan Hahmann, Matthias Arzt, Mette Handberg-Thorsager, Ko Sugawara, et al. 2025. ‚ÄúMastodon: The Command Center for Large-Scale Lineage-Tracing Microscopy Datasets.‚Äù bioRxiv, December, 2025.12.10.693416. https://doi.org/10.64898/2025.12.10.693416.\n\n\nSchindelin, Johannes, Ignacio Arganda-Carreras, Erwin Frise, Verena Kaynig, Mark Longair, Tobias Pietzsch, Stephan Preibisch, et al. 2012. ‚ÄúFiji: An Open-Source Platform for Biological-Image Analysis.‚Äù Nat. Methods 9 (June): 676‚Äì82. https://doi.org/10.1038/nmeth.2019.",
    "crumbs": [
      "Practicals",
      "Cell tracking using Mastodon in Fiji"
    ]
  },
  {
    "objectID": "practicals/practical_multiview/index.html",
    "href": "practicals/practical_multiview/index.html",
    "title": "Multiview reconstruction",
    "section": "",
    "text": "Multiview reconstruction\n\nDefining dataset\nresaving h5\nvisualizing\nregistering\nfusing.",
    "crumbs": [
      "Practicals",
      "Multiview reconstruction"
    ]
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Help",
    "section": "",
    "text": "Find answers to your questions about the course.\n\n\n\nInstitute\nTransportation stop\nTheory sessions: ‚Ä¶\nCoffee breaks: ‚Ä¶\nPoster sessions: ‚Ä¶\nPractical sessions: ‚Ä¶\nLunch breaks: ‚Ä¶\nDinner?\n\n\n\n\n\nBackground and base for practicals\n\n\n\n\n\nTwo per computer\nDetails of systems\n\n\n\n\n\nDefine achievable goal based on your needs and on what you want to learn.\nUse your own data or example data provided by organizers\n\n\n\n\n\n8 min + 2 min questions\n\n\n\n\n\nTime, location, etc",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#locations",
    "href": "help.html#locations",
    "title": "Help",
    "section": "",
    "text": "Institute\nTransportation stop\nTheory sessions: ‚Ä¶\nCoffee breaks: ‚Ä¶\nPoster sessions: ‚Ä¶\nPractical sessions: ‚Ä¶\nLunch breaks: ‚Ä¶\nDinner?",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#theory-sessions",
    "href": "help.html#theory-sessions",
    "title": "Help",
    "section": "",
    "text": "Background and base for practicals",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#practical-sessions",
    "href": "help.html#practical-sessions",
    "title": "Help",
    "section": "",
    "text": "Two per computer\nDetails of systems",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#project-work",
    "href": "help.html#project-work",
    "title": "Help",
    "section": "",
    "text": "Define achievable goal based on your needs and on what you want to learn.\nUse your own data or example data provided by organizers",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#group-presentations",
    "href": "help.html#group-presentations",
    "title": "Help",
    "section": "",
    "text": "8 min + 2 min questions",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "help.html#group-dinner",
    "href": "help.html#group-dinner",
    "title": "Help",
    "section": "",
    "text": "Time, location, etc",
    "crumbs": [
      "Help"
    ]
  },
  {
    "objectID": "internal/quarto.html",
    "href": "internal/quarto.html",
    "title": "Quarto reference guide",
    "section": "",
    "text": "Here are some of the markdown basics we can use with Quarto.\n\n\nitalics, bold, bold italics, superscript2 / subscript2, strikethrough, verbatim code\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nTask 1\nTask 2\n\n\nterm\n\ndefinition\n\n\n\nBlockquote\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: An Elephant\n\n\n\nThis is illustrated well by Figure¬†1.\n\n\n\n\n\n\nTable¬†1: My Caption\n\n\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\nSee Table¬†1.\n\n\n\nLife is good (Weigert et al. 2018). (bibkey should be in references.bib)\n\n\n\nProgram Resources\n\n\n\nHere is a footnote reference,1 and another.2.\nHere is an inline note.3\n\n\n\ninline math: \\(E = mc^{2}\\)\ndisplay math:\n\\[E = mc^{2}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote callout block.\n\n\n\n\n\n\n\n\nTip\n\n\n\nTip callout block.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning callout block.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nCaution callout block.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant callout block.",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#text-formatting",
    "href": "internal/quarto.html#text-formatting",
    "title": "Quarto reference guide",
    "section": "",
    "text": "italics, bold, bold italics, superscript2 / subscript2, strikethrough, verbatim code\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nTask 1\nTask 2\n\n\nterm\n\ndefinition\n\n\n\nBlockquote",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#figures",
    "href": "internal/quarto.html#figures",
    "title": "Quarto reference guide",
    "section": "",
    "text": "Figure¬†1: An Elephant\n\n\n\nThis is illustrated well by Figure¬†1.",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#tables",
    "href": "internal/quarto.html#tables",
    "title": "Quarto reference guide",
    "section": "",
    "text": "Table¬†1: My Caption\n\n\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\nSee Table¬†1.",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#citations",
    "href": "internal/quarto.html#citations",
    "title": "Quarto reference guide",
    "section": "",
    "text": "Life is good (Weigert et al. 2018). (bibkey should be in references.bib)",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#buttons",
    "href": "internal/quarto.html#buttons",
    "title": "Quarto reference guide",
    "section": "",
    "text": "Program Resources",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#footnotes",
    "href": "internal/quarto.html#footnotes",
    "title": "Quarto reference guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere is the footnote.‚Ü©Ô∏é\nHere‚Äôs one with multiple blocks.‚Ü©Ô∏é\nInlines notes are easier to write, since you don‚Äôt have to pick an identifier and move down to type the note.‚Ü©Ô∏é",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#code-blocks-and-math",
    "href": "internal/quarto.html#code-blocks-and-math",
    "title": "Quarto reference guide",
    "section": "",
    "text": "inline math: \\(E = mc^{2}\\)\ndisplay math:\n\\[E = mc^{2}\\]",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "internal/quarto.html#callout-blocks",
    "href": "internal/quarto.html#callout-blocks",
    "title": "Quarto reference guide",
    "section": "",
    "text": "Note\n\n\n\nNote callout block.\n\n\n\n\n\n\n\n\nTip\n\n\n\nTip callout block.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning callout block.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nCaution callout block.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant callout block.",
    "crumbs": [
      "Internal",
      "Quarto reference guide"
    ]
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "Program",
    "section": "",
    "text": "Note\n\n\n\nThis is the current program. Edit this page! The original draft program is here.\n\n\n\n\nMonday, 5 Jan 2026\n\n\n\n09:00‚Äì09:15 - Welcome session and course overview\n09:15‚Äì10:00 - Concepts in light-sheet microscopy (Marina)\n10:00‚Äì11:00 - Experimental design and sample mounting (Marina)\n\n\n\n\n\n\n\n\n11:45‚Äì12:30 - Visualization and processing of digital images (Agust√≠n)\n12:30‚Äì13:00 - Best practices in microscopy data management (Bruno)\n\n\n\n\n\n\n\n\n14:00‚Äì14:30 - [Talk from companies] (Company 1)\n14:30‚Äì15:30 - Visualization of 2D images (Agust√≠n)\n15:30‚Äì17:30 - Visualization of 3D images (Bruno)\n\n\n\n\n\nTuesday, 6 Jan 2026\n\n\n\n09:00‚Äì10:00 - Image processing and analysis (Agust√≠n)\n10:00‚Äì11:00 - Multiview reconstruction and tissue cartography (Bruno)\n\n\n\n\n\n\n\n\n\n11:45‚Äì13:00 - Multiview reconstruction (Bruno)\n\n\n\n\n\n\n\n\n\n14:00‚Äì14:30 - [Talk from companies] (Company 2-Galenica)\n14:30‚Äì16:00 - Pre-processing, denoising, segmentation (Marina)\n16:00‚Äì17:30 - ImageJ macro programming (Marina)\n\n\n\n\n\nWednesday, 7 Jan 2026\n\n\n\n\n09:00‚Äì09:30 - [Talk from companies] (Company 3-Bruker)\n09:30‚Äì11:00 - Deep learning (Agust√≠n/Bruno)\n\n\n\n\n\n\n\n\n11:30‚Äì13:00 - 3D segmentation using machine/deep learning (Marina/Agust√≠n)\n\n\n\n\n\n\n\n\n\n14:00‚Äì16:00 - Tissue cartography (Bruno)\n16:00‚Äì17:30 - Cell tracking (Bruno)\n\n\n\n\n\nThursday, 8 Jan 2026\n\n\n\n09:00‚Äì09:30 - Talk Bruno (Bruno)\n09:30‚Äì10:00 - Talk Marina (Marina)\n10:00‚Äì10:30 - Talk Charlotte (Charlotte)\n10:30‚Äì11:00 - Talk Leo (Leo)\n\n\n\n\n\n\n\n\n11:30‚Äì13:00 - Project work (Groups)\n\n\n\n\n\n14:00‚Äì17:30 - Project work (Groups)\n\n\n\n\n\nFriday, 9 Jan 2026\n\n\n\n09:00‚Äì11:00 - Project work (Groups)\n\n\n\n\n\n\n\n\n11:30‚Äì13:00 - Project work (Groups)\n\n\n\n\n\n14:00‚Äì16:30 - Group presentations (Groups)\n16:30‚Äì17:00 - Closing remarks (Organizers)\n17:00‚Äìonwards - Group dinner (Everyone)",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "program.html#day-1-light-sheet-principles-and-digital-images",
    "href": "program.html#day-1-light-sheet-principles-and-digital-images",
    "title": "Program",
    "section": "",
    "text": "Monday, 5 Jan 2026\n\n\n\n09:00‚Äì09:15 - Welcome session and course overview\n09:15‚Äì10:00 - Concepts in light-sheet microscopy (Marina)\n10:00‚Äì11:00 - Experimental design and sample mounting (Marina)\n\n\n\n\n\n\n\n\n11:45‚Äì12:30 - Visualization and processing of digital images (Agust√≠n)\n12:30‚Äì13:00 - Best practices in microscopy data management (Bruno)\n\n\n\n\n\n\n\n\n14:00‚Äì14:30 - [Talk from companies] (Company 1)\n14:30‚Äì15:30 - Visualization of 2D images (Agust√≠n)\n15:30‚Äì17:30 - Visualization of 3D images (Bruno)",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "program.html#day-2-image-processing-and-multiview-reconstruction",
    "href": "program.html#day-2-image-processing-and-multiview-reconstruction",
    "title": "Program",
    "section": "",
    "text": "Tuesday, 6 Jan 2026\n\n\n\n09:00‚Äì10:00 - Image processing and analysis (Agust√≠n)\n10:00‚Äì11:00 - Multiview reconstruction and tissue cartography (Bruno)\n\n\n\n\n\n\n\n\n\n11:45‚Äì13:00 - Multiview reconstruction (Bruno)\n\n\n\n\n\n\n\n\n\n14:00‚Äì14:30 - [Talk from companies] (Company 2-Galenica)\n14:30‚Äì16:00 - Pre-processing, denoising, segmentation (Marina)\n16:00‚Äì17:30 - ImageJ macro programming (Marina)",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "program.html#day-3-machine-learning-and-advanced-workflows",
    "href": "program.html#day-3-machine-learning-and-advanced-workflows",
    "title": "Program",
    "section": "",
    "text": "Wednesday, 7 Jan 2026\n\n\n\n\n09:00‚Äì09:30 - [Talk from companies] (Company 3-Bruker)\n09:30‚Äì11:00 - Deep learning (Agust√≠n/Bruno)\n\n\n\n\n\n\n\n\n11:30‚Äì13:00 - 3D segmentation using machine/deep learning (Marina/Agust√≠n)\n\n\n\n\n\n\n\n\n\n14:00‚Äì16:00 - Tissue cartography (Bruno)\n16:00‚Äì17:30 - Cell tracking (Bruno)",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "program.html#day-4-scientific-applications-and-project-work",
    "href": "program.html#day-4-scientific-applications-and-project-work",
    "title": "Program",
    "section": "",
    "text": "Thursday, 8 Jan 2026\n\n\n\n09:00‚Äì09:30 - Talk Bruno (Bruno)\n09:30‚Äì10:00 - Talk Marina (Marina)\n10:00‚Äì10:30 - Talk Charlotte (Charlotte)\n10:30‚Äì11:00 - Talk Leo (Leo)\n\n\n\n\n\n\n\n\n11:30‚Äì13:00 - Project work (Groups)\n\n\n\n\n\n14:00‚Äì17:30 - Project work (Groups)",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "program.html#day-5-project-work-and-presentations",
    "href": "program.html#day-5-project-work-and-presentations",
    "title": "Program",
    "section": "",
    "text": "Friday, 9 Jan 2026\n\n\n\n09:00‚Äì11:00 - Project work (Groups)\n\n\n\n\n\n\n\n\n11:30‚Äì13:00 - Project work (Groups)\n\n\n\n\n\n14:00‚Äì16:30 - Group presentations (Groups)\n16:30‚Äì17:00 - Closing remarks (Organizers)\n17:00‚Äìonwards - Group dinner (Everyone)",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "internal/draft_program.html",
    "href": "internal/draft_program.html",
    "title": "Original draft program",
    "section": "",
    "text": "Caution\n\n\n\nPlease don‚Äôt edit this page. The current program is here.\n\n\nInitial draft of the program written by Marina. Keeping it here as a reference.\n\n\n\nüß† Morning Session\n- Welcome & Course Overview\n- Principles of Light-Sheet Microscopy\n- Optical setup & acquisition strategies\n- Experiment planning and sample mounting\n- Common image artifacts and how to avoid/fix them\n- Introduction to light-sheet datasets: file types, metadata, scale, volume/time complexity\nüñ•Ô∏è Afternoon Workshop\n- Multiview reconstruction in Fiji\n- Hands-on with 3D visualization in Fiji and Napari\n\n\n\nüß† Morning Session\n- Fundamentals of BioImage Analysis\n- Image types and bit depth\n- Noise, background correction, filters\n- Thresholding, segmentation basics (pixel vs object)\n- ROI handling and masks\n- Overview of available open-source tools\nüñ•Ô∏è Afternoon Workshop\n- Segmentation workflows in Fiji and Napari (2D/3D)\n- Intro to cell tracking methods\n\n\n\nüß† Morning Session\n- Introduction to AI and deep learning in microscopy\n- When and why to use DL models\n- Overview of StarDist, CellPose\nüñ•Ô∏è Afternoon Workshop\n- Using BioImage Model Zoo models with Napari\n- Hands-on with Labkit and ilastik (interactive annotation & classification)\n- Deploying pre-trained models on user data\n- Optional: Train your own simple model (time permitting)\n\n\n\nüß† Morning Session\n- Research applications of BioImage Analysis\n- Talks or case studies using light-sheet imaging\n- Highlight multi-disciplinary projects (e.g.¬†developmental biology, neuroscience, plant science)\n- Tips for designing an effective analysis pipeline\nüñ•Ô∏è Afternoon Workshop\n- Begin working on personal projects or example datasets\n- Q&A with instructors (project clinic)\n- Begin structuring project presentations (suggested format below)\n\n\n\nüß† Morning Session\n- Continue work on projects\n- Finalize analysis and prepare presentations\n- Instructor support for polishing visuals and conclusions\nüñ•Ô∏è Afternoon Session\n- Student Presentations (10 min each + 5 min Q&A)\n- Suggested format:\n1. Dataset and biological question\n2. Analysis goal\n3. Method and tools used\n4. Results\n5. Challenges & next steps\n- Group Discussion and Feedback\n- Closing Remarks & Certificate Distribution\n- Group Dinner üéâ",
    "crumbs": [
      "Internal",
      "Original draft program"
    ]
  },
  {
    "objectID": "internal/draft_program.html#day-1-introduction-to-light-sheet-and-3d-visualization",
    "href": "internal/draft_program.html#day-1-introduction-to-light-sheet-and-3d-visualization",
    "title": "Original draft program",
    "section": "",
    "text": "üß† Morning Session\n- Welcome & Course Overview\n- Principles of Light-Sheet Microscopy\n- Optical setup & acquisition strategies\n- Experiment planning and sample mounting\n- Common image artifacts and how to avoid/fix them\n- Introduction to light-sheet datasets: file types, metadata, scale, volume/time complexity\nüñ•Ô∏è Afternoon Workshop\n- Multiview reconstruction in Fiji\n- Hands-on with 3D visualization in Fiji and Napari",
    "crumbs": [
      "Internal",
      "Original draft program"
    ]
  },
  {
    "objectID": "internal/draft_program.html#day-2-image-analysis-fundamentals",
    "href": "internal/draft_program.html#day-2-image-analysis-fundamentals",
    "title": "Original draft program",
    "section": "",
    "text": "üß† Morning Session\n- Fundamentals of BioImage Analysis\n- Image types and bit depth\n- Noise, background correction, filters\n- Thresholding, segmentation basics (pixel vs object)\n- ROI handling and masks\n- Overview of available open-source tools\nüñ•Ô∏è Afternoon Workshop\n- Segmentation workflows in Fiji and Napari (2D/3D)\n- Intro to cell tracking methods",
    "crumbs": [
      "Internal",
      "Original draft program"
    ]
  },
  {
    "objectID": "internal/draft_program.html#day-3-machine-learning-and-ai-for-image-analysis",
    "href": "internal/draft_program.html#day-3-machine-learning-and-ai-for-image-analysis",
    "title": "Original draft program",
    "section": "",
    "text": "üß† Morning Session\n- Introduction to AI and deep learning in microscopy\n- When and why to use DL models\n- Overview of StarDist, CellPose\nüñ•Ô∏è Afternoon Workshop\n- Using BioImage Model Zoo models with Napari\n- Hands-on with Labkit and ilastik (interactive annotation & classification)\n- Deploying pre-trained models on user data\n- Optional: Train your own simple model (time permitting)",
    "crumbs": [
      "Internal",
      "Original draft program"
    ]
  },
  {
    "objectID": "internal/draft_program.html#day-4-applications-independent-project-work",
    "href": "internal/draft_program.html#day-4-applications-independent-project-work",
    "title": "Original draft program",
    "section": "",
    "text": "üß† Morning Session\n- Research applications of BioImage Analysis\n- Talks or case studies using light-sheet imaging\n- Highlight multi-disciplinary projects (e.g.¬†developmental biology, neuroscience, plant science)\n- Tips for designing an effective analysis pipeline\nüñ•Ô∏è Afternoon Workshop\n- Begin working on personal projects or example datasets\n- Q&A with instructors (project clinic)\n- Begin structuring project presentations (suggested format below)",
    "crumbs": [
      "Internal",
      "Original draft program"
    ]
  },
  {
    "objectID": "internal/draft_program.html#day-5-final-projects-presentations",
    "href": "internal/draft_program.html#day-5-final-projects-presentations",
    "title": "Original draft program",
    "section": "",
    "text": "üß† Morning Session\n- Continue work on projects\n- Finalize analysis and prepare presentations\n- Instructor support for polishing visuals and conclusions\nüñ•Ô∏è Afternoon Session\n- Student Presentations (10 min each + 5 min Q&A)\n- Suggested format:\n1. Dataset and biological question\n2. Analysis goal\n3. Method and tools used\n4. Results\n5. Challenges & next steps\n- Group Discussion and Feedback\n- Closing Remarks & Certificate Distribution\n- Group Dinner üéâ",
    "crumbs": [
      "Internal",
      "Original draft program"
    ]
  },
  {
    "objectID": "internal/presentation.html#getting-up",
    "href": "internal/presentation.html#getting-up",
    "title": "Example presentation",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed",
    "crumbs": [
      "Internal",
      "Example presentation"
    ]
  },
  {
    "objectID": "internal/presentation.html#breakfast",
    "href": "internal/presentation.html#breakfast",
    "title": "Example presentation",
    "section": "Breakfast",
    "text": "Breakfast\n\nEat eggs\nDrink coffee",
    "crumbs": [
      "Internal",
      "Example presentation"
    ]
  },
  {
    "objectID": "internal/presentation.html#dinner",
    "href": "internal/presentation.html#dinner",
    "title": "Example presentation",
    "section": "Dinner",
    "text": "Dinner\n\nEat spaghetti\nDrink wine",
    "crumbs": [
      "Internal",
      "Example presentation"
    ]
  },
  {
    "objectID": "internal/presentation.html#going-to-sleep",
    "href": "internal/presentation.html#going-to-sleep",
    "title": "Example presentation",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep",
    "crumbs": [
      "Internal",
      "Example presentation"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Compilation of tools and resources for image analysis focused on what we will use.\nTODO: Add more links for tools and resources here.\n\n\nDesktop software for image analysis.\n\nhttps://fiji.sc/\nhttps://napari.org/\n\n\n\n\nSpaces to interact and discuss about image analysis.\n\nhttps://forum.image.sc/\nhttps://imagesc.zulipchat.com/\n\n\n\n\nOther curated lists of tools and resources for scientific image analysis.\n\nhttps://github.com/epfl-center-for-imaging/awesome-scientific-image-analysis/\nhttps://github.com/hallvaaw/awesome-biological-image-analysis/",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#general",
    "href": "resources.html#general",
    "title": "Resources",
    "section": "",
    "text": "Desktop software for image analysis.\n\nhttps://fiji.sc/\nhttps://napari.org/",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#community",
    "href": "resources.html#community",
    "title": "Resources",
    "section": "",
    "text": "Spaces to interact and discuss about image analysis.\n\nhttps://forum.image.sc/\nhttps://imagesc.zulipchat.com/",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#compilations",
    "href": "resources.html#compilations",
    "title": "Resources",
    "section": "",
    "text": "Other curated lists of tools and resources for scientific image analysis.\n\nhttps://github.com/epfl-center-for-imaging/awesome-scientific-image-analysis/\nhttps://github.com/hallvaaw/awesome-biological-image-analysis/",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "practicals/practical_macros/index.html",
    "href": "practicals/practical_macros/index.html",
    "title": "ImageJ macros",
    "section": "",
    "text": "ImageJ macros\nMarina could do this with no prob. https://f1000research.com/slides/11-973 - Why? - Types of macros - How to record",
    "crumbs": [
      "Practicals",
      "ImageJ macros"
    ]
  },
  {
    "objectID": "practicals/practical_3d/index.html",
    "href": "practicals/practical_3d/index.html",
    "title": "Visualization of 3D images",
    "section": "",
    "text": "Visualization of 3D images\n\nMax projections\n\nOrthogonal views\n\nReslicing\n\nBigData viewer\n\n3D script",
    "crumbs": [
      "Practicals",
      "Visualization of 3D images"
    ]
  },
  {
    "objectID": "practicals/practical_cartography/index.html",
    "href": "practicals/practical_cartography/index.html",
    "title": "Tissue cartography",
    "section": "",
    "text": "Tissue cartography\n\nPipelines\nSetup\nSegmentation\nSurface detection\nMesh editing\nMesh painting\nMap projection\nExport\nMeasurements\nhttps://zenodo.org/records/7628300",
    "crumbs": [
      "Practicals",
      "Tissue cartography"
    ]
  },
  {
    "objectID": "practicals/practical_deep_learning/index.html",
    "href": "practicals/practical_deep_learning/index.html",
    "title": "3D segmentation using machine/deep learning",
    "section": "",
    "text": "3D segmentation using machine/deep learning\nPractical - Machine and Deep learning - Segmentation of 3D structures (2h)\n\nPixel classification in labkit and napari (MC) (30 min) https://scads.github.io/napari-tutorial-2023/intro.html https://www.youtube.com/watch?v=QDS5t7oZH-c https://f1000research.com/slides/12-972\nCellpose - BioImage Zoo (pre-trained models, fine tunning) Is this Agus? (1 hr)",
    "crumbs": [
      "Practicals",
      "3D segmentation using machine/deep learning"
    ]
  },
  {
    "objectID": "talks/talk_multiview_cartography.html",
    "href": "talks/talk_multiview_cartography.html",
    "title": "Multiview reconstruction and tissue cartography",
    "section": "",
    "text": "Multiview reconstruction and tissue cartography\n\nPrinciples of multiview acquisition\nOptimal settings\nExperimental optimization\nBigStitcher\nRegistration\nFusion/Deconvolution\nTissue cartography\nMaps\nSoftware tools",
    "crumbs": [
      "Talks",
      "Multiview reconstruction and tissue cartography"
    ]
  },
  {
    "objectID": "talks/talk_data_management.html",
    "href": "talks/talk_data_management.html",
    "title": "Best practices in microscopy data management",
    "section": "",
    "text": "Best practices in microscopy data management\n\nNumbered directories\nFile names\nREADMEs",
    "crumbs": [
      "Talks",
      "Best practices in microscopy data management"
    ]
  },
  {
    "objectID": "talks/talk_image_processing.html",
    "href": "talks/talk_image_processing.html",
    "title": "Image processing and analysis",
    "section": "",
    "text": "Image processing and analysis\n\nWhat is Bioimage Analysis?\nWhat is a workflow or a pipeline?\nDenoising\nBackground subtraction\nTheory of Macro programming and Napari assistant (mention checklist)\nSegmentation (only classical algorithms) and labeling (MC Found this presentation https://imagej.net/media/arganda-carreras-segmentation-bioimage-course-mdc-berlin-2016.pdf)\nMorphological operations?\nBIA ecosystem: open source tools, licensed tools, image.sc\nhttps://zenodo.org/records/16920518",
    "crumbs": [
      "Talks",
      "Image processing and analysis"
    ]
  },
  {
    "objectID": "talks/talk_lightsheet_concepts.html",
    "href": "talks/talk_lightsheet_concepts.html",
    "title": "Concepts in light-sheet microscopy",
    "section": "",
    "text": "Concepts in light-sheet microscopy\n\nConcept behind LSM in contrast with other imaging methods (Talk adapted from Sebastian Bundschuh, to be uploaded soon)",
    "crumbs": [
      "Talks",
      "Concepts in light-sheet microscopy"
    ]
  },
  {
    "objectID": "talks/talk_deep_learning.html",
    "href": "talks/talk_deep_learning.html",
    "title": "Deep learning",
    "section": "",
    "text": "Deep learning\n\nDeep Learning Theory\n\nCellpose (? Maybe AC) (Check trackmate for 3D CellPose)\n\nStardist\n\nPlantSeg (MC)\n\nBioImage Zoo (AC)\n\nCARE - noise2void (BV)",
    "crumbs": [
      "Talks",
      "Deep learning"
    ]
  }
]